# å‡è®¾ä½ å·²ç»è¿è¡Œäº†run_torch_bayesian_optimizationå‡½æ•°
# å¹¶ä¸”å®ƒå·²ç»ä¿å­˜äº†'./output/best_model.pth'æ–‡ä»¶

import torch
import torch.nn.functional as F
from sklearn.base import BaseEstimator, ClassifierMixin
import numpy as np
import pandas as pd
from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, confusion_matrix, classification_report
from sklearn.inspection import PartialDependenceDisplay
import os
import matplotlib.pyplot as plt
import seaborn as sns

from model_utils import create_model, create_optimizer, train_and_evaluate

def print_cuda_memory_info(device, context=""):
    """æ‰“å°CUDAå†…å­˜ä½¿ç”¨ä¿¡æ¯"""
    if device.type == "cuda":
        allocated = torch.cuda.memory_allocated(device)
        reserved = torch.cuda.memory_reserved(device)
        total = torch.cuda.get_device_properties(device).total_memory
        
        print(f"ğŸ”§ CUDA Memory {context}:")
        print(f"  Allocated: {allocated / 1024**2:.1f} MB")
        print(f"  Reserved: {reserved / 1024**2:.1f} MB")
        print(f"  Total: {total / 1024**3:.1f} GB")
        print(f"  Usage: {allocated / total * 100:.1f}%")

def cleanup_cuda_memory(device):
    """æ¸…ç†CUDAå†…å­˜"""
    if device.type == "cuda":
        torch.cuda.empty_cache()
        torch.cuda.synchronize()  # ç­‰å¾…æ‰€æœ‰CUDAæ“ä½œå®Œæˆ

def load_best_model(model_path, input_dim, output_dim, device="auto"):
    param_path = os.path.join(model_path, 'bayesian_best_params.csv')
    model_state_path = os.path.join(model_path, 'best_model.pth')

    if not os.path.exists(param_path) or not os.path.exists(model_state_path):
        raise FileNotFoundError("Best model parameters or model weights not found.")
    
    # è®¾å¤‡æ£€æµ‹å’Œé€‰æ‹©
    if device == "auto":
        if torch.cuda.is_available():
            device = torch.device("cuda")
            print(f"âœ“ CUDA available! Using GPU for evaluation")
        else:
            device = torch.device("cpu")
            print("âœ“ CUDA not available, using CPU for evaluation")
    else:
        device = torch.device(device)
        if device.type == "cuda" and not torch.cuda.is_available():
            print("âš  CUDA requested but not available, falling back to CPU")
            device = torch.device("cpu")
    
    # 1. åŠ è½½æœ€ä½³å‚æ•°
    params_df = pd.read_csv(param_path)
    # å°† DataFrame è½¬æ¢ä¸ºå­—å…¸ï¼Œé”®ä¸º 'parameter'ï¼Œå€¼ä¸º 'value'
    best_params_raw = params_df.set_index('parameter')['value'].to_dict()

    # æ„å»ºéšè—å±‚é…ç½®
    hidden_config = [int(best_params_raw['hidden_size_1'])]
    if best_params_raw['hidden_size_2'] > 8:
        hidden_config.append(int(best_params_raw['hidden_size_2']))
    if best_params_raw['hidden_size_3'] > 8:
        hidden_config.append(int(best_params_raw['hidden_size_3']))
    if best_params_raw['hidden_size_4'] > 8:
        hidden_config.append(int(best_params_raw['hidden_size_4']))
    # æ„å»º dropout é…ç½®
    dropout_config = [best_params_raw['dropout_rate']] * len(hidden_config)
    use_batch_norm = best_params_raw['use_batch_norm_num'] > 0.5

    # åˆ›å»ºæ¨¡å‹
    final_model = create_model(input_dim, hidden_config, dropout_config, output_dim, use_batch_norm, "relu")
    # 3. åŠ è½½ä¿å­˜çš„æƒé‡
    final_model.load_state_dict(torch.load(model_state_path, map_location=device))
    # ç§»åŠ¨æ¨¡å‹åˆ°æŒ‡å®šè®¾å¤‡
    final_model = final_model.to(device)

    # 4. å°†æ¨¡å‹è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼å¹¶è¿›è¡Œæ¨ç†
    final_model.eval() 

    print("âœ“ Best model loaded successfully.")
    print("Model Architecture:")
    print(f"  Input features: {input_dim}")
    print(f"  Hidden layers: {hidden_config}")
    print(f"  Output classes: {output_dim}")
    print(f"  Dropout rate: {best_params_raw['dropout_rate']:.4f}")
    print(f"  Batch Normalization: {'YES' if use_batch_norm else 'NO'}")
    print(f"  Device: {device}")
    
    # æ˜¾ç¤ºå†…å­˜ä½¿ç”¨æƒ…å†µ
    if device.type == "cuda":
        print_cuda_memory_info(device, "after loading model")
    
    return final_model, device

def get_permutation_importance(model, X_test, y_test, feature_names, metric='auc', n_repeats=3, device=None):
    """
    è®¡ç®—åŸºäºæ’åˆ—çš„ç‰¹å¾é‡è¦æ€§ã€‚
    Args:
        model (torch.nn.Module): è®­ç»ƒå¥½çš„æ¨¡å‹ã€‚
        X_test (torch.Tensor): æµ‹è¯•é›†ç‰¹å¾ã€‚
        y_test (torch.Tensor): æµ‹è¯•é›†æ ‡ç­¾ã€‚
        feature_names (list): ç‰¹å¾åç§°åˆ—è¡¨ã€‚
        metric (str): è¯„ä¼°æŒ‡æ ‡ ('auc' æˆ– 'accuracy')ã€‚
        n_repeats (int): é‡å¤æ‰“ä¹±çš„æ¬¡æ•°ã€‚
        device: è®¡ç®—è®¾å¤‡
    Returns:
        pd.DataFrame: åŒ…å«ç‰¹å¾é‡è¦æ€§çš„DataFrameã€‚
    """
    if device is None:
        device = X_test.device
    
    # æ¸…ç†CUDAç¼“å­˜
    if device.type == "cuda":
        torch.cuda.empty_cache()
        
    model.eval()
    
    # ç¡®ä¿æ•°æ®åœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Š
    X_test = X_test.to(device)
    y_test = y_test.to(device)
    
    # è·å–åŸºå‡†åˆ†æ•°
    with torch.no_grad():
        base_preds = F.softmax(model(X_test), dim=1).cpu().numpy()
    
    y_test_cpu = y_test.cpu().numpy()
    
    if metric == 'auc':
        if len(np.unique(y_test_cpu)) == 2:
            base_score = roc_auc_score(y_test_cpu, base_preds[:, 1])
        else:
            raise ValueError("AUC metric is only supported for binary classification.")
    elif metric == 'accuracy':
        base_score = accuracy_score(y_test_cpu, np.argmax(base_preds, axis=1))
    else:
        raise ValueError("Unsupported metric for permutation importance.")

    importance_scores = []

    for i in range(X_test.shape[1]):
        feature_scores = []
        for _ in range(n_repeats):
            # å¤åˆ¶æ•°æ®ä»¥é¿å…ä¿®æ”¹åŸå§‹Tensor
            X_shuffled = X_test.clone()
            
            # æ‰“ä¹±å½“å‰ç‰¹å¾åˆ—
            permuted_indices = torch.randperm(X_shuffled.size(0))
            X_shuffled[:, i] = X_shuffled[:, i][permuted_indices]
            
            # é‡æ–°è®¡ç®—åˆ†æ•°
            with torch.no_grad():
                shuffled_preds = F.softmax(model(X_shuffled), dim=1).cpu().numpy()
            
            if metric == 'auc':
                score = roc_auc_score(y_test_cpu, shuffled_preds[:, 1])
            else: # accuracy
                score = accuracy_score(y_test_cpu, np.argmax(shuffled_preds, axis=1))
            
            feature_scores.append(base_score - score)
        
        importance_scores.append(np.mean(feature_scores))
    
    importance_df = pd.DataFrame({
        'feature': feature_names,
        'importance': importance_scores
    }).sort_values(by='importance', ascending=False)
    
    # æ¸…ç†CUDAå†…å­˜
    if device.type == "cuda":
        torch.cuda.empty_cache()
    
    return importance_df

def create_manual_pdp_plots(model, X_data, feature_names, device, output_dir, n_points=50):
    """
    æ‰‹åŠ¨åˆ›å»ºæ›´é«˜è´¨é‡çš„PDPå›¾ï¼Œå®Œå…¨ç»•è¿‡sklearn
    """
    print("Creating manual PDP plots...")
    
    # æ¸…ç†ç°æœ‰å›¾å½¢å’ŒCUDAç¼“å­˜
    plt.close('all')
    if device.type == "cuda":
        torch.cuda.empty_cache()
    
    n_features = len(feature_names)
    n_cols = 3
    n_rows = (n_features + n_cols - 1) // n_cols
    
    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 4 * n_rows))
    if n_rows == 1:
        axes = axes.reshape(1, -1)
    axes = axes.flatten()
    
    model.eval()
    
    for i, feature_name in enumerate(feature_names):
        try:
            # è·å–ç‰¹å¾å€¼èŒƒå›´
            feature_values = X_data[:, i]
            feature_min, feature_max = feature_values.min(), feature_values.max()
            
            # åˆ›å»ºç‰¹å¾å€¼ç½‘æ ¼
            feature_grid = np.linspace(feature_min, feature_max, n_points)
            
            # è®¡ç®—æ‰€æœ‰å…¶ä»–ç‰¹å¾çš„å‡å€¼æˆ–ä¸­ä½æ•°
            base_values = np.median(X_data, axis=0)  # ä½¿ç”¨ä¸­ä½æ•°æ›´ç¨³å¥
            
            # è®¡ç®—PDPå€¼
            pdp_values = []
            
            for val in feature_grid:
                # åˆ›å»ºä¸€æ‰¹æ ·æœ¬ï¼Œåªæ”¹å˜å½“å‰ç‰¹å¾
                batch_samples = np.tile(base_values, (X_data.shape[0], 1))
                batch_samples[:, i] = val
                
                # é¢„æµ‹
                with torch.no_grad():
                    batch_tensor = torch.tensor(batch_samples, dtype=torch.float32).to(device)
                    probs = torch.nn.functional.softmax(model(batch_tensor), dim=1).cpu().numpy()
                    # å–æ­£ç±»æ¦‚ç‡çš„å¹³å‡å€¼
                    avg_prob = np.mean(probs[:, 1])
                    pdp_values.append(avg_prob)
            
            # ç»˜åˆ¶PDPæ›²çº¿
            axes[i].plot(feature_grid, pdp_values, linewidth=2, color='blue', marker='o', markersize=2)
            axes[i].set_title(f'PDP: {feature_name}', fontsize=12, fontweight='bold')
            axes[i].set_xlabel(feature_name, fontsize=10)
            axes[i].set_ylabel('Average Prediction', fontsize=10)
            axes[i].grid(True, alpha=0.3)
            
            # æ·»åŠ ç‰¹å¾åˆ†å¸ƒçš„ç›´æ–¹å›¾ä½œä¸ºèƒŒæ™¯
            ax2 = axes[i].twinx()
            ax2.hist(feature_values, bins=20, alpha=0.2, color='gray', density=True)
            ax2.set_ylabel('Density', fontsize=8, color='gray')
            ax2.tick_params(axis='y', labelsize=8, colors='gray')
            
        except Exception as e:
            print(f"Failed to create PDP for {feature_name}: {str(e)}")
            axes[i].text(0.5, 0.5, f'Error: {feature_name}', transform=axes[i].transAxes, 
                        ha='center', va='center', fontsize=10)
    
    # éšè—å¤šä½™çš„å­å›¾
    for i in range(n_features, len(axes)):
        axes[i].set_visible(False)
    
    plt.tight_layout()
    pdp_path = os.path.join(output_dir, "manual_pdp_plots.png")
    plt.savefig(pdp_path, dpi=300, bbox_inches='tight')
    plt.close()
    
    # æ¸…ç†CUDAå†…å­˜
    if device.type == "cuda":
        torch.cuda.empty_cache()
    
    return pdp_path

def create_ice_plots(model, X_data, feature_names, device, output_dir, n_samples=100, n_points=30):
    """
    åˆ›å»ºIndividual Conditional Expectation (ICE) å›¾
    """
    print("Creating ICE plots...")
    
    # æ¸…ç†ç°æœ‰å›¾å½¢å’ŒCUDAç¼“å­˜
    plt.close('all')
    if device.type == "cuda":
        torch.cuda.empty_cache()
    
    # é€‰æ‹©å‰6ä¸ªæœ€é‡è¦çš„ç‰¹å¾
    selected_features = feature_names[:6]
    
    fig, axes = plt.subplots(2, 3, figsize=(15, 8))
    axes = axes.flatten()
    
    model.eval()
    
    # éšæœºé€‰æ‹©æ ·æœ¬å­é›†
    n_total_samples = X_data.shape[0]
    if n_total_samples > n_samples:
        sample_indices = np.random.choice(n_total_samples, n_samples, replace=False)
        sample_data = X_data[sample_indices]
    else:
        sample_data = X_data
    
    for plot_idx, feature_name in enumerate(selected_features):
        feature_idx = feature_names.index(feature_name)
        
        try:
            # è·å–ç‰¹å¾å€¼èŒƒå›´
            feature_values = X_data[:, feature_idx]
            feature_min, feature_max = feature_values.min(), feature_values.max()
            feature_grid = np.linspace(feature_min, feature_max, n_points)
            
            # ä¸ºæ¯ä¸ªæ ·æœ¬è®¡ç®—ICEæ›²çº¿
            ice_curves = []
            
            for sample in sample_data:
                ice_values = []
                for val in feature_grid:
                    modified_sample = sample.copy()
                    modified_sample[feature_idx] = val
                    
                    with torch.no_grad():
                        sample_tensor = torch.tensor(modified_sample.reshape(1, -1), dtype=torch.float32).to(device)
                        prob = torch.nn.functional.softmax(model(sample_tensor), dim=1).cpu().numpy()
                        ice_values.append(prob[0, 1])  # æ­£ç±»æ¦‚ç‡
                
                ice_curves.append(ice_values)
                axes[plot_idx].plot(feature_grid, ice_values, alpha=0.1, color='blue', linewidth=0.5)
            
            # è®¡ç®—å¹¶ç»˜åˆ¶å¹³å‡PDPæ›²çº¿
            pdp_curve = np.mean(ice_curves, axis=0)
            axes[plot_idx].plot(feature_grid, pdp_curve, color='red', linewidth=3, label='PDP (Average)')
            
            axes[plot_idx].set_title(f'ICE & PDP: {feature_name}', fontsize=12, fontweight='bold')
            axes[plot_idx].set_xlabel(feature_name, fontsize=10)
            axes[plot_idx].set_ylabel('Prediction', fontsize=10)
            axes[plot_idx].grid(True, alpha=0.3)
            axes[plot_idx].legend()
            
        except Exception as e:
            print(f"Failed to create ICE plot for {feature_name}: {str(e)}")
            axes[plot_idx].text(0.5, 0.5, f'Error: {feature_name}', transform=axes[plot_idx].transAxes, 
                               ha='center', va='center', fontsize=10)
    
    plt.tight_layout()
    ice_path = os.path.join(output_dir, "ice_plots.png")
    plt.savefig(ice_path, dpi=300, bbox_inches='tight')
    plt.close()
    
    # æ¸…ç†CUDAå†…å­˜
    if device.type == "cuda":
        torch.cuda.empty_cache()
    
    return ice_path

def create_interaction_plots(model, X_data, feature_names, device, output_dir):
    """
    åˆ›å»ºå‰å‡ ä¸ªé‡è¦ç‰¹å¾ä¹‹é—´çš„äº¤äº’æ•ˆåº”å›¾
    """
    print("Creating feature interaction plots...")
    
    # æ¸…ç†ç°æœ‰å›¾å½¢å’ŒCUDAç¼“å­˜
    plt.close('all')
    if device.type == "cuda":
        torch.cuda.empty_cache()
    
    # é€‰æ‹©å‰4ä¸ªç‰¹å¾è¿›è¡Œä¸¤ä¸¤äº¤äº’åˆ†æ
    top_features = feature_names[:4]
    
    fig, axes = plt.subplots(2, 3, figsize=(18, 10))
    axes = axes.flatten()
    
    model.eval()
    plot_idx = 0
    
    for i in range(len(top_features)):
        for j in range(i+1, len(top_features)):
            if plot_idx >= 6:
                break
                
            feat1_name = top_features[i]
            feat2_name = top_features[j]
            feat1_idx = feature_names.index(feat1_name)
            feat2_idx = feature_names.index(feat2_name)
            
            try:
                # è·å–ç‰¹å¾èŒƒå›´
                feat1_values = X_data[:, feat1_idx]
                feat2_values = X_data[:, feat2_idx]
                
                feat1_grid = np.linspace(feat1_values.min(), feat1_values.max(), 20)
                feat2_grid = np.linspace(feat2_values.min(), feat2_values.max(), 20)
                
                # åˆ›å»ºç½‘æ ¼
                F1, F2 = np.meshgrid(feat1_grid, feat2_grid)
                
                # è®¡ç®—äº¤äº’æ•ˆåº”
                base_sample = np.median(X_data, axis=0)
                interaction_surface = np.zeros_like(F1)
                
                for ii in range(F1.shape[0]):
                    for jj in range(F1.shape[1]):
                        sample = base_sample.copy()
                        sample[feat1_idx] = F1[ii, jj]
                        sample[feat2_idx] = F2[ii, jj]
                        
                        with torch.no_grad():
                            sample_tensor = torch.tensor(sample.reshape(1, -1), dtype=torch.float32).to(device)
                            prob = torch.nn.functional.softmax(model(sample_tensor), dim=1).cpu().numpy()
                            interaction_surface[ii, jj] = prob[0, 1]
                
                # ç»˜åˆ¶çƒ­åŠ›å›¾
                im = axes[plot_idx].contourf(F1, F2, interaction_surface, levels=20, cmap='viridis')
                axes[plot_idx].set_title(f'{feat1_name} Ã— {feat2_name}', fontsize=12, fontweight='bold')
                axes[plot_idx].set_xlabel(feat1_name, fontsize=10)
                axes[plot_idx].set_ylabel(feat2_name, fontsize=10)
                
                # æ·»åŠ é¢œè‰²æ¡
                plt.colorbar(im, ax=axes[plot_idx], shrink=0.8)
                
            except Exception as e:
                print(f"Failed to create interaction plot for {feat1_name} Ã— {feat2_name}: {str(e)}")
                axes[plot_idx].text(0.5, 0.5, f'Error\n{feat1_name} Ã— {feat2_name}', 
                                   transform=axes[plot_idx].transAxes, ha='center', va='center', fontsize=10)
            
            plot_idx += 1
    
    # éšè—å¤šä½™çš„å­å›¾
    for idx in range(plot_idx, 6):
        axes[idx].set_visible(False)
    
    plt.tight_layout()
    interaction_path = os.path.join(output_dir, "interaction_plots.png")
    plt.savefig(interaction_path, dpi=300, bbox_inches='tight')
    plt.close()
    
    # æ¸…ç†CUDAå†…å­˜
    if device.type == "cuda":
        torch.cuda.empty_cache()
    
    return interaction_path

class TorchModelWrapper(BaseEstimator, ClassifierMixin):
    def __init__(self, model, device=None):
        self.model = model
        self.device = device if device is not None else next(model.parameters()).device
        self.model.eval()
        # æ·»åŠ å¿…è¦çš„sklearnå±æ€§
        self.classes_ = None
        self.n_features_in_ = None
        self.feature_names_in_ = None
        self._fitted = False
        
    def fit(self, X, y):
        """è™šæ‹Ÿçš„fitæ–¹æ³•ï¼Œå› ä¸ºæ¨¡å‹å·²ç»è®­ç»ƒå¥½äº†"""
        # è®¾ç½®classes_å±æ€§ï¼Œè¿™æ˜¯sklearnè¦æ±‚çš„
        if hasattr(y, 'numpy'):
            y_array = y.numpy() if hasattr(y, 'numpy') else y
        else:
            y_array = np.array(y)
        
        self.classes_ = np.unique(y_array)
        self.n_features_in_ = X.shape[1] if hasattr(X, 'shape') else len(X[0])
        self._fitted = True
        
        # æ·»åŠ feature_names_in_å¦‚æœå¯ç”¨
        if hasattr(X, 'columns'):
            self.feature_names_in_ = np.array(X.columns)
        elif isinstance(X, np.ndarray):
            self.feature_names_in_ = np.array([f'x{i}' for i in range(self.n_features_in_)])
            
        return self
        
    def predict(self, X):
        """é¢„æµ‹ç±»åˆ«"""
        import torch
        import numpy as np
        
        # æ£€æŸ¥æ˜¯å¦å·²æ‹Ÿåˆ
        if not self._fitted:
            raise ValueError("This TorchModelWrapper instance is not fitted yet.")
            
        # ç¡®ä¿è¾“å…¥æ˜¯numpyæ•°ç»„
        if not isinstance(X, np.ndarray):
            X = np.array(X)
            
        with torch.no_grad():
            X_tensor = torch.tensor(X, dtype=torch.float32).to(self.device)
            outputs = self.model(X_tensor)
            predictions = torch.argmax(outputs, dim=1).cpu().numpy()
        return predictions
        
    def predict_proba(self, X):
        """é¢„æµ‹æ¦‚ç‡"""
        import torch
        import numpy as np
        
        # æ£€æŸ¥æ˜¯å¦å·²æ‹Ÿåˆ
        if not self._fitted:
            raise ValueError("This TorchModelWrapper instance is not fitted yet.")
            
        # ç¡®ä¿è¾“å…¥æ˜¯numpyæ•°ç»„
        if not isinstance(X, np.ndarray):
            X = np.array(X)
            
        with torch.no_grad():
            X_tensor = torch.tensor(X, dtype=torch.float32).to(self.device)
            probs = torch.nn.functional.softmax(self.model(X_tensor), dim=1).cpu().numpy()
        return probs
        
    def _check_is_fitted(self):
        """æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²æ‹Ÿåˆçš„å†…éƒ¨æ–¹æ³•"""
        return self._fitted

def run_torch_evaluation(training_output_dir, test_data, target, device="auto"):
    """åŠ è½½æœ€ä½³æ¨¡å‹å¹¶åœ¨æµ‹è¯•é›†ä¸Šè¿›è¡Œè¯„ä¼°"""

    # é…ç½®matplotlibä»¥é¿å…å†…å­˜æ³„æ¼
    import matplotlib
    matplotlib.pyplot.ioff()  # å…³é—­äº¤äº’æ¨¡å¼
    
    # æ¸…ç†å¯èƒ½å­˜åœ¨çš„å›¾å½¢
    plt.close('all')
    
     # æ•°æ®å‡†å¤‡
    features = [col for col in test_data.columns if col != target]
    input_dim = len(features)
    unique_labels = sorted(test_data[target].unique())
    output_dim = len(unique_labels)
    
    # è®¾å¤‡æ£€æµ‹å’Œé€‰æ‹©
    if device == "auto":
        if torch.cuda.is_available():
            device = torch.device("cuda")
            print(f"âœ“ CUDA available! Using GPU for evaluation")
            # æ¸…ç†åˆå§‹CUDAå†…å­˜
            torch.cuda.empty_cache()
            print(f"  Initial GPU Memory: {torch.cuda.memory_allocated() / 1024**2:.1f} MB")
        else:
            device = torch.device("cpu")
            print("âœ“ CUDA not available, using CPU for evaluation")
    else:
        device = torch.device(device)
        if device.type == "cuda" and not torch.cuda.is_available():
            print("âš  CUDA requested but not available, falling back to CPU")
            device = torch.device("cpu")
        elif device.type == "cuda":
            torch.cuda.empty_cache()
            print(f"  Initial GPU Memory: {torch.cuda.memory_allocated() / 1024**2:.1f} MB")
    
    # è½¬æ¢ä¸ºtorch tensorså¹¶ç§»åŠ¨åˆ°è®¾å¤‡
    X_test = torch.tensor(test_data[features].values, dtype=torch.float32).to(device)
    # æ ‡ç­¾æ˜ å°„ï¼ˆä»0å¼€å§‹ï¼‰
    label_mapping = {label: i for i, label in enumerate(unique_labels)}
    y_test = torch.tensor([label_mapping[label] for label in test_data[target]], dtype=torch.long).to(device)
    
    print(f"Unique labels: {unique_labels}")
    print("Label mapping (Original â†’ Encoded):")
    for original_label, encoded_label in label_mapping.items():
        print(f"  {original_label} â†’ {encoded_label}")
    print(f"Input features: {input_dim}, Output classes: {output_dim}")
    print(f"Test: {len(test_data)} samples")
    print(f"Device: {device}")

    final_model, model_device = load_best_model(training_output_dir, input_dim, output_dim, device)

    print("--- æ­£åœ¨è¯„ä¼°æ¨¡å‹æ€§èƒ½ ---")
    
    # 3. è®¡ç®—é¢„æµ‹ç»“æœ
    with torch.no_grad():
        predictions = final_model(X_test)
        probs = F.softmax(predictions, dim=1).cpu().numpy()
        preds_classes = np.argmax(probs, axis=1)

    y_test_np_classes = y_test.cpu().numpy()

    # 4. è®¡ç®—å¹¶æ‰“å°è¯„ä¼°æŒ‡æ ‡ï¼Œå¹¶ä¿å­˜åˆ°æœ¬åœ°
    metrics_txt = []
    if len(unique_labels) == 2:
        auc_score = roc_auc_score(y_test_np_classes, probs[:, 1])
        print(f"Test AUC Score: {auc_score:.4f}")
        metrics_txt.append(f"Test AUC Score: {auc_score:.4f}")
    else:
        auc_score = None
    accuracy = accuracy_score(y_test_np_classes, preds_classes)
    precision = precision_score(y_test_np_classes, preds_classes, average='binary')
    recall = recall_score(y_test_np_classes, preds_classes, average='binary')
    metrics_txt.append(f"Test Accuracy: {accuracy:.4f}")
    metrics_txt.append(f"Test Precision: {precision:.4f}")
    metrics_txt.append(f"Test Recall: {recall:.4f}")
    
    cm = confusion_matrix(y_test_np_classes, preds_classes)
    metrics_txt.append("\nConfusion Matrix:")
    metrics_txt.append(str(cm))
    print(f"Test Accuracy: {accuracy:.4f}")
    print(f"Test Precision: {precision:.4f}")
    print(f"Test Recall: {recall:.4f}")
    print("\nConfusion Matrix:")
    print(cm)
    
    cls_report = classification_report(y_test_np_classes, preds_classes, target_names=[str(l) for l in unique_labels])
    metrics_txt.append("\nClassification Report:")
    metrics_txt.append(cls_report)
    print("\nClassification Report:")
    print(cls_report)
    
    # ä¿å­˜åˆ°æœ¬åœ°txtæ–‡ä»¶
    metrics_path = os.path.join(training_output_dir, "metrics_and_confusion_matrix.txt")
    with open(metrics_path, "w", encoding="utf-8") as f:
        f.write("\n".join(metrics_txt))
    print(f"âœ“ Metrics and confusion matrix saved to {metrics_path}")
    
    # 5. è®¡ç®—å¹¶ä¿å­˜æ’åˆ—ç‰¹å¾é‡è¦æ€§
    print("\n--- æ­£åœ¨è®¡ç®—æ’åˆ—ç‰¹å¾é‡è¦æ€§ ---")
    imp_df = get_permutation_importance(final_model, X_test, y_test, feature_names=features, metric='auc', device=device)
    print("Permutation Feature Importance:")
    print(imp_df)
    
    os.makedirs(training_output_dir, exist_ok=True)
    imp_df.to_csv(os.path.join(training_output_dir, "feature_importance.csv"), index=False)
    print(f"âœ“ Feature importance saved to {os.path.join(training_output_dir, 'feature_importance.csv')}")

    # 6. å¯è§†åŒ–ç‰¹å¾é‡è¦æ€§
    print("--- æ­£åœ¨ç”Ÿæˆç‰¹å¾é‡è¦æ€§å›¾ ---")
    plt.figure(figsize=(10, 6))
    sns.barplot(x='importance', y='feature', data=imp_df)
    plt.title("Permutation Feature Importance")
    plt.xlabel("AUC Drop")
    plt.ylabel("Feature")
    plt.tight_layout()
    plt.savefig(os.path.join(training_output_dir, "feature_importance.png"), dpi=300, bbox_inches='tight')
    plt.close()  # æ·»åŠ ç¼ºå¤±çš„å›¾å½¢å…³é—­
    
    print(f"âœ“ Feature importance plot saved to {os.path.join(training_output_dir, 'feature_importance.png')}")

    print("--- æ­£åœ¨ç”Ÿæˆå¤šç§å¯è§£é‡Šæ€§å›¾è¡¨ ---")
    
    # é¦–å…ˆå°è¯•æˆ‘ä»¬çš„è‡ªå®šä¹‰PDPå›¾
    try:
        manual_pdp_path = create_manual_pdp_plots(
            final_model, 
            X_test.cpu().numpy(), 
            features, 
            device, 
            training_output_dir
        )
        print(f"âœ“ Manual PDP plots saved to {manual_pdp_path}")
    except Exception as e:
        print(f"âœ— Manual PDP plots failed: {str(e)}")
    
    # åˆ›å»ºICEå›¾
    try:
        ice_path = create_ice_plots(
            final_model, 
            X_test.cpu().numpy(), 
            features, 
            device, 
            training_output_dir
        )
        print(f"âœ“ ICE plots saved to {ice_path}")
    except Exception as e:
        print(f"âœ— ICE plots failed: {str(e)}")
    
    # åˆ›å»ºç‰¹å¾äº¤äº’å›¾
    try:
        interaction_path = create_interaction_plots(
            final_model, 
            X_test.cpu().numpy(), 
            features, 
            device, 
            training_output_dir
        )
        print(f"âœ“ Interaction plots saved to {interaction_path}")
    except Exception as e:
        print(f"âœ— Interaction plots failed: {str(e)}")

    # æœ€ç»ˆæ¸…ç†æ‰€æœ‰matplotlibå›¾å½¢
    plt.close('all')
    
    # æœ€ç»ˆCUDAå†…å­˜æ¸…ç†
    if device.type == "cuda":
        torch.cuda.empty_cache()
        final_memory = torch.cuda.memory_allocated()
        print(f"âœ“ Final GPU Memory: {final_memory / 1024**2:.1f} MB")
        
        # æ˜¾ç¤ºæ€»å†…å­˜ä½¿ç”¨æƒ…å†µ
        total_memory = torch.cuda.get_device_properties(device).total_memory
        print(f"âœ“ GPU Memory Usage: {final_memory / total_memory * 100:.1f}% of {total_memory / 1024**3:.1f} GB")
    
    return {
        'auc': auc_score if len(unique_labels) == 2 else None,
        'accuracy': accuracy,
        'precision': precision,
        'recall': recall,
        'feature_importance': imp_df
    }